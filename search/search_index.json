{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started","text":""},{"location":"#htrflow_core","title":"htrflow_core","text":"<p>A short description of the project</p>"},{"location":"#installation","title":"Installation","text":"<p>Installation can be done using pypi:</p> <pre><code>pip install htrflow_core\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo.</p>"},{"location":"api/results/","title":"Results documentation","text":""},{"location":"api/results/#htrflow_core.results.RecognizedText","title":"<code>RecognizedText</code>  <code>dataclass</code>","text":"<p>Recognized text class</p> <p>This class represents a result from a text recognition model.</p> <p>Attributes:</p> Name Type Description <code>texts</code> <code>Sequence[str]</code> <p>A sequence of candidate texts</p> <code>scores</code> <code>Sequence[float]</code> <p>The scores of the candidate texts</p> Source code in <code>src/htrflow_core/results.py</code> <pre><code>@dataclass\nclass RecognizedText:\n    \"\"\"Recognized text class\n\n    This class represents a result from a text recognition model.\n\n    Attributes:\n        texts: A sequence of candidate texts\n        scores: The scores of the candidate texts\n    \"\"\"\n    texts: Sequence[str]\n    scores: Sequence[float]\n\n    def top_candidate(self):\n        \"\"\"The best candidate text\"\"\"\n        return self.texts[self.scores.index(self.top_score())]\n\n    def top_score(self):\n        \"\"\"The highest score\"\"\"\n        return max(self.scores)\n</code></pre>"},{"location":"api/results/#htrflow_core.results.RecognizedText.top_candidate","title":"<code>top_candidate()</code>","text":"<p>The best candidate text</p> Source code in <code>src/htrflow_core/results.py</code> <pre><code>def top_candidate(self):\n    \"\"\"The best candidate text\"\"\"\n    return self.texts[self.scores.index(self.top_score())]\n</code></pre>"},{"location":"api/results/#htrflow_core.results.RecognizedText.top_score","title":"<code>top_score()</code>","text":"<p>The highest score</p> Source code in <code>src/htrflow_core/results.py</code> <pre><code>def top_score(self):\n    \"\"\"The highest score\"\"\"\n    return max(self.scores)\n</code></pre>"},{"location":"api/results/#htrflow_core.results.Result","title":"<code>Result</code>  <code>dataclass</code>","text":"<p>Result class</p> <p>This class bundles segmentation and text recognition results</p> <p>Returns:</p> Name Type Description <code>image</code> <p>The original imaage</p> <code>metadata</code> <p>Metadata associated with the result</p> <code>segments</code> <p>Segments (may be empty)</p> <code>texts</code> <p>Texts (may be empty)</p> Source code in <code>src/htrflow_core/results.py</code> <pre><code>@dataclass\nclass Result:\n    \"\"\"Result class\n\n    This class bundles segmentation and text recognition results\n\n    Returns:\n        image: The original imaage\n        metadata: Metadata associated with the result\n        segments: Segments (may be empty)\n        texts: Texts (may be empty)\n    \"\"\"\n\n    image: np.ndarray\n    metadata: dict\n    segments: Sequence[Segment] = field(default_factory=list)\n    texts: Sequence[RecognizedText] = field(default_factory=list)\n\n    @classmethod\n    def text_recognition_result(cls, image: np.ndarray, metadata: dict, text: RecognizedText) -&gt; \"Result\":\n        \"\"\"Create a text recognition result\n\n        Arguments:\n            image: The original image\n            metadata: Result metadata\n            text: The recognized text\n\n        Returns:\n            A Result instance with the specified data and no segments.\n        \"\"\"\n        return cls(image, metadata, texts=[text])\n\n    @classmethod\n    def segmentation_result(cls, image: np.ndarray, metadata: dict, segments: Sequence[Segment]) -&gt; \"Result\":\n        \"\"\"Create a segmentation result\n\n        Arguments:\n            image: The original image\n            metadata: Result metadata\n            segments: The segments\n\n        Returns:\n            A Result instance with the specified data and no texts.\n        \"\"\"\n        return cls(image, metadata, segments=segments)\n</code></pre>"},{"location":"api/results/#htrflow_core.results.Result.segmentation_result","title":"<code>segmentation_result(image, metadata, segments)</code>  <code>classmethod</code>","text":"<p>Create a segmentation result</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>The original image</p> required <code>metadata</code> <code>dict</code> <p>Result metadata</p> required <code>segments</code> <code>Sequence[Segment]</code> <p>The segments</p> required <p>Returns:</p> Type Description <code>Result</code> <p>A Result instance with the specified data and no texts.</p> Source code in <code>src/htrflow_core/results.py</code> <pre><code>@classmethod\ndef segmentation_result(cls, image: np.ndarray, metadata: dict, segments: Sequence[Segment]) -&gt; \"Result\":\n    \"\"\"Create a segmentation result\n\n    Arguments:\n        image: The original image\n        metadata: Result metadata\n        segments: The segments\n\n    Returns:\n        A Result instance with the specified data and no texts.\n    \"\"\"\n    return cls(image, metadata, segments=segments)\n</code></pre>"},{"location":"api/results/#htrflow_core.results.Result.text_recognition_result","title":"<code>text_recognition_result(image, metadata, text)</code>  <code>classmethod</code>","text":"<p>Create a text recognition result</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>The original image</p> required <code>metadata</code> <code>dict</code> <p>Result metadata</p> required <code>text</code> <code>RecognizedText</code> <p>The recognized text</p> required <p>Returns:</p> Type Description <code>Result</code> <p>A Result instance with the specified data and no segments.</p> Source code in <code>src/htrflow_core/results.py</code> <pre><code>@classmethod\ndef text_recognition_result(cls, image: np.ndarray, metadata: dict, text: RecognizedText) -&gt; \"Result\":\n    \"\"\"Create a text recognition result\n\n    Arguments:\n        image: The original image\n        metadata: Result metadata\n        text: The recognized text\n\n    Returns:\n        A Result instance with the specified data and no segments.\n    \"\"\"\n    return cls(image, metadata, texts=[text])\n</code></pre>"},{"location":"api/results/#htrflow_core.results.Segment","title":"<code>Segment</code>  <code>dataclass</code>","text":"<p>Segment class</p> <p>Attributes:</p> Name Type Description <code>bbox</code> <code>tuple[int, int, int, int]</code> <p>The segment's bounding box as a tuple of coordinates (x1, x2, y1, y2)</p> <code>mask</code> <code>Optional[ndarray]</code> <p>The segment's mask, if available. The mask is relative to the bounding box.</p> <code>score</code> <code>Optional[float]</code> <p>Segment confidence score</p> <code>class_label</code> <code>Optional[str]</code> <p>Segment label, if available</p> <code>polygon</code> <code>list[tuple]</code> <p>An approximation of the segment mask, !relative to the parent!</p> Source code in <code>src/htrflow_core/results.py</code> <pre><code>@dataclass\nclass Segment:\n    \"\"\"Segment class\n\n    Attributes:\n        bbox: The segment's bounding box as a tuple of coordinates (x1, x2, y1, y2)\n        mask: The segment's mask, if available. The mask is relative to the bounding box.\n        score: Segment confidence score\n        class_label: Segment label, if available\n        polygon: An approximation of the segment mask, !relative to the parent!\n    \"\"\"\n\n    bbox: tuple[int, int, int, int]\n    mask: Optional[np.ndarray]\n    polygon: list[tuple] = None\n    score: Optional[float] = None\n    class_label: Optional[str] = None\n    # baseline: list[tuple] ?\n\n    @classmethod\n    def from_bbox(cls, bbox, **kwargs):\n        \"\"\"Create a segment from a bounding box\"\"\"\n        mask = None\n        polygon = image.bbox2polygon(bbox)\n        return cls(bbox, mask, polygon, **kwargs)\n\n    @classmethod\n    def from_mask(cls, mask, **kwargs):\n        \"\"\"Create a segment from a mask\n\n        Args:\n            mask: A binary mask, of same shape as original image.\n        \"\"\"\n        bbox = image.mask2bbox(mask)\n        polygon = image.mask2polygon(mask)\n        cropped_mask = image.crop(mask, bbox)\n        return cls(bbox, cropped_mask, polygon, **kwargs)\n\n    @classmethod\n    def from_baseline(cls, baseline, **kwargs):\n        \"\"\"Create a segment from a baseline\"\"\"\n        raise NotImplementedError()\n</code></pre>"},{"location":"api/results/#htrflow_core.results.Segment.from_baseline","title":"<code>from_baseline(baseline, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a segment from a baseline</p> Source code in <code>src/htrflow_core/results.py</code> <pre><code>@classmethod\ndef from_baseline(cls, baseline, **kwargs):\n    \"\"\"Create a segment from a baseline\"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"api/results/#htrflow_core.results.Segment.from_bbox","title":"<code>from_bbox(bbox, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a segment from a bounding box</p> Source code in <code>src/htrflow_core/results.py</code> <pre><code>@classmethod\ndef from_bbox(cls, bbox, **kwargs):\n    \"\"\"Create a segment from a bounding box\"\"\"\n    mask = None\n    polygon = image.bbox2polygon(bbox)\n    return cls(bbox, mask, polygon, **kwargs)\n</code></pre>"},{"location":"api/results/#htrflow_core.results.Segment.from_mask","title":"<code>from_mask(mask, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a segment from a mask</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <p>A binary mask, of same shape as original image.</p> required Source code in <code>src/htrflow_core/results.py</code> <pre><code>@classmethod\ndef from_mask(cls, mask, **kwargs):\n    \"\"\"Create a segment from a mask\n\n    Args:\n        mask: A binary mask, of same shape as original image.\n    \"\"\"\n    bbox = image.mask2bbox(mask)\n    polygon = image.mask2polygon(mask)\n    cropped_mask = image.crop(mask, bbox)\n    return cls(bbox, cropped_mask, polygon, **kwargs)\n</code></pre>"},{"location":"api/volume/","title":"Volume documentation","text":"<p>This module holds the base data structures</p>"},{"location":"api/volume/#htrflow_core.volume.BaseDocumentNode","title":"<code>BaseDocumentNode</code>","text":"<p>             Bases: <code>Node</code>, <code>ABC</code></p> <p>Extension of Node class with functionality related to documents</p> Source code in <code>src/htrflow_core/volume.py</code> <pre><code>class BaseDocumentNode(Node, ABC):\n    \"\"\"Extension of Node class with functionality related to documents\"\"\"\n\n    height: int\n    width: int\n    coord: Point\n    label: str\n    polygon: list[tuple[int, int]]\n    bbox: tuple[int, int, int, int]\n    children: Sequence[\"RegionNode\"]\n    recognized_text: Optional[RecognizedText]\n\n    def __str__(self) -&gt; str:\n        return f'{self.height}x{self.width} region ({self.label}) at ({self.coord.x}, {self.coord.y})'\n\n    @abstractproperty\n    def image(self):\n        pass\n\n    @abstractmethod\n    def add_text(self, recognized_text: RecognizedText):\n        \"\"\"Add text to this node\"\"\"\n\n    def segment(self, segments: Sequence[Segment]):\n        \"\"\"Segment this node\"\"\"\n        children = []\n        for segment in segments:\n            children.append(RegionNode(segment, self))\n        self.children = children\n\n    def contains_text(self) -&gt; bool:\n        return any(child.contains_text() for child in self.children)\n\n    def has_regions(self) -&gt; bool:\n        return all(not child.is_leaf() for child in self.children)\n\n    def is_line(self):\n        return False\n\n    def segments(self):\n        for leaf in self.leaves():\n            yield leaf.image\n</code></pre>"},{"location":"api/volume/#htrflow_core.volume.BaseDocumentNode.add_text","title":"<code>add_text(recognized_text)</code>  <code>abstractmethod</code>","text":"<p>Add text to this node</p> Source code in <code>src/htrflow_core/volume.py</code> <pre><code>@abstractmethod\ndef add_text(self, recognized_text: RecognizedText):\n    \"\"\"Add text to this node\"\"\"\n</code></pre>"},{"location":"api/volume/#htrflow_core.volume.BaseDocumentNode.segment","title":"<code>segment(segments)</code>","text":"<p>Segment this node</p> Source code in <code>src/htrflow_core/volume.py</code> <pre><code>def segment(self, segments: Sequence[Segment]):\n    \"\"\"Segment this node\"\"\"\n    children = []\n    for segment in segments:\n        children.append(RegionNode(segment, self))\n    self.children = children\n</code></pre>"},{"location":"api/volume/#htrflow_core.volume.Node","title":"<code>Node</code>","text":"<p>Node class</p> Source code in <code>src/htrflow_core/volume.py</code> <pre><code>class Node:\n    \"\"\"Node class\"\"\"\n\n    parent: Optional[\"Node\"]\n    children: Sequence[\"Node\"]\n    depth: int\n\n    def __init__(self, parent: Optional[\"Node\"] = None):\n        self.parent = parent\n        self.children = []\n        self.depth = parent.depth + 1 if parent else 0\n\n    def __getitem__(self, i):\n        if isinstance(i, int):\n            return self.children[i]\n        i, *rest = i\n        return self.children[i][rest] if rest else self.children[i]\n\n    def leaves(self): # -&gt; Sequence[Self]:\n        \"\"\"Return the leaf nodes attached to this node\"\"\"\n        nodes = [] if self.children else [self]\n        for child in self.children:\n            nodes.extend(child.leaves())\n        return nodes\n\n    def traverse(self, filter: Optional[Callable[[\"Node\"], bool]] = None) -&gt; Sequence[\"Node\"]:\n        \"\"\"Return all nodes attached to this node\"\"\"\n        nodes = [self] if (filter is None or filter(self)) else []\n        for child in self.children:\n            nodes.extend(child.traverse(filter=filter))\n        return nodes\n\n    def tree2str(self, sep: str=\"\", is_last: bool=True) -&gt; str:\n        \"\"\"Return a string representation of this node and its decendants\"\"\"\n        lines = [sep + (\"\u2514\u2500\u2500\" if is_last else \"\u251c\u2500\u2500\") + str(self)]\n        sep += \"    \" if is_last else \"\u2502   \"\n        for child in self.children:\n            lines.append(child.tree2str(sep, child == self.children[-1]))\n        return \"\\n\".join(lines).strip(\"\u2514\u2500\u2500\")\n\n    def is_leaf(self) -&gt; bool:\n        return not self.children\n</code></pre>"},{"location":"api/volume/#htrflow_core.volume.Node.leaves","title":"<code>leaves()</code>","text":"<p>Return the leaf nodes attached to this node</p> Source code in <code>src/htrflow_core/volume.py</code> <pre><code>def leaves(self): # -&gt; Sequence[Self]:\n    \"\"\"Return the leaf nodes attached to this node\"\"\"\n    nodes = [] if self.children else [self]\n    for child in self.children:\n        nodes.extend(child.leaves())\n    return nodes\n</code></pre>"},{"location":"api/volume/#htrflow_core.volume.Node.traverse","title":"<code>traverse(filter=None)</code>","text":"<p>Return all nodes attached to this node</p> Source code in <code>src/htrflow_core/volume.py</code> <pre><code>def traverse(self, filter: Optional[Callable[[\"Node\"], bool]] = None) -&gt; Sequence[\"Node\"]:\n    \"\"\"Return all nodes attached to this node\"\"\"\n    nodes = [self] if (filter is None or filter(self)) else []\n    for child in self.children:\n        nodes.extend(child.traverse(filter=filter))\n    return nodes\n</code></pre>"},{"location":"api/volume/#htrflow_core.volume.Node.tree2str","title":"<code>tree2str(sep='', is_last=True)</code>","text":"<p>Return a string representation of this node and its decendants</p> Source code in <code>src/htrflow_core/volume.py</code> <pre><code>def tree2str(self, sep: str=\"\", is_last: bool=True) -&gt; str:\n    \"\"\"Return a string representation of this node and its decendants\"\"\"\n    lines = [sep + (\"\u2514\u2500\u2500\" if is_last else \"\u251c\u2500\u2500\") + str(self)]\n    sep += \"    \" if is_last else \"\u2502   \"\n    for child in self.children:\n        lines.append(child.tree2str(sep, child == self.children[-1]))\n    return \"\\n\".join(lines).strip(\"\u2514\u2500\u2500\")\n</code></pre>"},{"location":"api/volume/#htrflow_core.volume.PageNode","title":"<code>PageNode</code>","text":"<p>             Bases: <code>BaseDocumentNode</code></p> <p>A node representing a page / input image</p> Source code in <code>src/htrflow_core/volume.py</code> <pre><code>class PageNode(BaseDocumentNode):\n    \"\"\"A node representing a page / input image\"\"\"\n\n    recognized_text = None\n    _segment = None\n\n    def __init__(self, image_path: str):\n        self._image = cv2.imread(image_path)\n        self.image_path = image_path\n        self.height, self.width = self.image.shape[:2]\n        self.coord = Point(0, 0)\n        self.polygon = [(0, 0), (0, self.height), (self.width, self.height), (self.width, 0)]\n        self.bbox = (0, self.width, 0, self.height)\n\n        # Extract image name and remove file extension (`path/to/image.jpg` -&gt; `image`)\n        self.image_name = os.path.basename(image_path).split(\".\")[0]\n        self.label = self.image_name\n        super().__init__()\n\n    @property\n    def image(self):\n        return self._image\n\n    def add_text(self, recognized_text: RecognizedText):\n        child = RegionNode(Segment.from_bbox(self.bbox), self)\n        self.children = [child]\n        child.add_text(recognized_text)\n</code></pre>"},{"location":"api/volume/#htrflow_core.volume.RegionNode","title":"<code>RegionNode</code>","text":"<p>             Bases: <code>BaseDocumentNode</code></p> <p>A node representing a segment of a page</p> Source code in <code>src/htrflow_core/volume.py</code> <pre><code>class RegionNode(BaseDocumentNode):\n    \"\"\"A node representing a segment of a page\"\"\"\n\n    _segment: Segment\n    parent: BaseDocumentNode\n\n    DEFAULT_LABEL = \"region\"\n\n    def __init__(self, segment: Segment, parent: BaseDocumentNode):\n        super().__init__(parent)\n        self._segment = segment\n        self.recognized_text = None\n        self.label = segment.class_label if segment.class_label else RegionNode.DEFAULT_LABEL\n        x1, x2, y1, y2 = segment.bbox\n        self.height = y2 - y1\n        self.width = x2 - x1\n        self.polygon = [(x + parent.coord.x, y + parent.coord.y) for x, y in segment.polygon]\n        self.bbox = (x1 + parent.coord.x, x2 + parent.coord.x, y1 + parent.coord.y, y2 + parent.coord.y)\n        self.coord = Point(parent.coord.x + x1, parent.coord.y + y1)\n\n    def __str__(self) -&gt; str:\n        if self.text:\n            return f'{super().__str__()}: \"{self.text}\"'\n        return super().__str__()\n\n    def add_text(self, recognized_text):\n        self.recognized_text = recognized_text\n\n    @property\n    def image(self):\n        \"\"\"The image this segment represents\"\"\"\n        img = image.crop(self.parent.image, self._segment.bbox)\n        if self._segment.mask is not None:\n            img = image.mask(img, self._segment.mask)\n        return img\n\n    @property\n    def text(self) -&gt; Optional[str]:\n        \"\"\"Return self.recognized_text.top_candidate() if available\"\"\"\n        if self.recognized_text:\n            return self.recognized_text.top_candidate()\n        return None\n\n    def contains_text(self) -&gt; bool:\n        if not self.children:\n            return self.text is not None\n        return super().contains_text()\n\n    def is_region(self) -&gt; bool:\n        return bool(self.children) and not self.text\n\n    def is_word(self) -&gt; bool:\n        \"\"\"True if this node represents a word\"\"\"\n        return self.is_text() and len(self.text.split()) == 1\n\n    def is_line(self):\n        \"\"\"True if this node represents a text line\"\"\"\n        return self.is_text() and len(self.text.split()) &gt; 1\n\n    def is_text(self):\n        \"\"\"True if this node represents text\"\"\"\n        return self.recognized_text is not None\n</code></pre>"},{"location":"api/volume/#htrflow_core.volume.RegionNode.image","title":"<code>image</code>  <code>property</code>","text":"<p>The image this segment represents</p>"},{"location":"api/volume/#htrflow_core.volume.RegionNode.text","title":"<code>text: Optional[str]</code>  <code>property</code>","text":"<p>Return self.recognized_text.top_candidate() if available</p>"},{"location":"api/volume/#htrflow_core.volume.RegionNode.is_line","title":"<code>is_line()</code>","text":"<p>True if this node represents a text line</p> Source code in <code>src/htrflow_core/volume.py</code> <pre><code>def is_line(self):\n    \"\"\"True if this node represents a text line\"\"\"\n    return self.is_text() and len(self.text.split()) &gt; 1\n</code></pre>"},{"location":"api/volume/#htrflow_core.volume.RegionNode.is_text","title":"<code>is_text()</code>","text":"<p>True if this node represents text</p> Source code in <code>src/htrflow_core/volume.py</code> <pre><code>def is_text(self):\n    \"\"\"True if this node represents text\"\"\"\n    return self.recognized_text is not None\n</code></pre>"},{"location":"api/volume/#htrflow_core.volume.RegionNode.is_word","title":"<code>is_word()</code>","text":"<p>True if this node represents a word</p> Source code in <code>src/htrflow_core/volume.py</code> <pre><code>def is_word(self) -&gt; bool:\n    \"\"\"True if this node represents a word\"\"\"\n    return self.is_text() and len(self.text.split()) == 1\n</code></pre>"},{"location":"api/volume/#htrflow_core.volume.Volume","title":"<code>Volume</code>","text":"<p>Class representing a collection of input images</p> Source code in <code>src/htrflow_core/volume.py</code> <pre><code>class Volume:\n\n    \"\"\"Class representing a collection of input images\"\"\"\n\n    def __init__(self, paths: Iterable[str], label: str=\"untitled_volume\"):\n        \"\"\"Initialize volume\n\n        Arguments:\n            paths: A list of paths to images\n            label: A label describing the volume (optional)\n        \"\"\"\n        self.pages = [PageNode(path) for path in paths]\n        self.label = label\n\n    @classmethod\n    def from_directory(cls, path: str) -&gt; \"Volume\":\n        \"\"\"Initialize a volume from a directory\n\n        Sets the volume label to the directory name.\n\n        Arguments:\n            path: A path to a directory of images.\n        \"\"\"\n        files = (os.path.join(path, file) for file in os.listdir(path))\n        label = os.path.basename(path)\n        return cls(files, label)\n\n    @classmethod\n    def from_pickle(cls, path: str) -&gt; \"Volume\":\n        \"\"\"Initialize a volume from a pickle file\n\n        Arguments:\n            path: A path to a previously pickled volume instance\n        \"\"\"\n        with open(path, 'rb') as f:\n            vol = pickle.load(f)\n        return vol\n\n    def pickle(self, directory: str=\".cache\", filename: Optional[str] = None):\n        \"\"\"Pickle volume\n\n        Arguments:\n            directory: Where to save the pickle file\n            filename: Name of pickle file, optional. Defaults to\n                \"volume_{volume label}.pickle\" if left as None\n\n        Returns:\n            The path to the pickled file.\n        \"\"\"\n        os.makedirs(directory, exist_ok=True)\n        filename = f\"volume_{self.label}.pickle\" if filename is None else filename\n        path = os.path.join(directory, filename)\n        with open(path, 'wb') as f:\n            pickle.dump(self, f)\n        return path\n\n    def __getitem__(self, i):\n        if isinstance(i, Iterable):\n            i, *rest = i\n            return self.pages[i].__getitem__(rest)\n        return self.pages[i]\n\n    def __iter__(self):\n        return self.pages.__iter__()\n\n    def __str__(self):\n        return f\"Volume label: {self.label}\\nVolume tree:\\n\" + \"\\n\".join(page.tree2str() for page in self.pages)\n\n    def images(self):  # -&gt; Generator[np.ndarray]:\n        \"\"\"Yields the volume's original input images\"\"\"\n        for page in self.pages:\n            yield page.image\n\n    def leaves(self): # -&gt; Iterable[BaseDocumentNode]:\n        return chain.from_iterable(page.leaves() for page in self.pages)\n\n    def traverse(self):\n        return chain.from_iterable(page.traverse() for page in self.pages)\n\n    def segments(self, depth: Optional[int] = None): # -&gt; Iterable[np.ndarray]:\n        \"\"\"Yields the volume's segments at `depth`\n\n        Args:\n            depth (int | None): Which depth segments to yield. Defaults to None, which\n                returns the leaf nodes (maximum depth).\n        \"\"\"\n\n        if depth is None:\n            for node in self.leaves():\n                yield node.image\n        else:\n            for page in self.pages:\n                for node in page.traverse(lambda node: node.depth == depth):\n                    yield node.image\n\n    def update(self, results: list[Result]) -&gt; None:\n        \"\"\"\n        Update the volume with model results\n\n        Arguments:\n            results: A list of results where the i:th result corresponds\n                to the volume's i:th leaf node.\n        \"\"\"\n        leaves = list(self.leaves())\n        if len(leaves) != len(results):\n            raise ValueError(f\"Size of input ({len(results)}) does not match \"\n                             f\"the size of the tree ({len(leaves)})\")\n\n        # Update the leaves of the tree\n        for leaf, result in zip(leaves, results):\n\n            # If the result has segments, segment the leaf\n            if result.segments:\n                leaf.segment(result.segments)\n\n            # If the result has texts, add them to the new leaves (which\n            # may be other than `leaves` if the result also had a segmentation)\n            if result.texts:\n                for new_leaf, text in zip(leaf.leaves(), result.texts):\n                    new_leaf.add_text(text)\n\n    def save(self, directory: str=\"outputs\", format_: Literal[\"alto\", \"page\", \"txt\"] = \"alto\") -&gt; None:\n        \"\"\"Save volume\n\n        Arguments:\n            directory: Output directory\n            format_: Output format\n        \"\"\"\n        serialization.save_volume(self, format_, directory)\n</code></pre>"},{"location":"api/volume/#htrflow_core.volume.Volume.__init__","title":"<code>__init__(paths, label='untitled_volume')</code>","text":"<p>Initialize volume</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>Iterable[str]</code> <p>A list of paths to images</p> required <code>label</code> <code>str</code> <p>A label describing the volume (optional)</p> <code>'untitled_volume'</code> Source code in <code>src/htrflow_core/volume.py</code> <pre><code>def __init__(self, paths: Iterable[str], label: str=\"untitled_volume\"):\n    \"\"\"Initialize volume\n\n    Arguments:\n        paths: A list of paths to images\n        label: A label describing the volume (optional)\n    \"\"\"\n    self.pages = [PageNode(path) for path in paths]\n    self.label = label\n</code></pre>"},{"location":"api/volume/#htrflow_core.volume.Volume.from_directory","title":"<code>from_directory(path)</code>  <code>classmethod</code>","text":"<p>Initialize a volume from a directory</p> <p>Sets the volume label to the directory name.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>A path to a directory of images.</p> required Source code in <code>src/htrflow_core/volume.py</code> <pre><code>@classmethod\ndef from_directory(cls, path: str) -&gt; \"Volume\":\n    \"\"\"Initialize a volume from a directory\n\n    Sets the volume label to the directory name.\n\n    Arguments:\n        path: A path to a directory of images.\n    \"\"\"\n    files = (os.path.join(path, file) for file in os.listdir(path))\n    label = os.path.basename(path)\n    return cls(files, label)\n</code></pre>"},{"location":"api/volume/#htrflow_core.volume.Volume.from_pickle","title":"<code>from_pickle(path)</code>  <code>classmethod</code>","text":"<p>Initialize a volume from a pickle file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>A path to a previously pickled volume instance</p> required Source code in <code>src/htrflow_core/volume.py</code> <pre><code>@classmethod\ndef from_pickle(cls, path: str) -&gt; \"Volume\":\n    \"\"\"Initialize a volume from a pickle file\n\n    Arguments:\n        path: A path to a previously pickled volume instance\n    \"\"\"\n    with open(path, 'rb') as f:\n        vol = pickle.load(f)\n    return vol\n</code></pre>"},{"location":"api/volume/#htrflow_core.volume.Volume.images","title":"<code>images()</code>","text":"<p>Yields the volume's original input images</p> Source code in <code>src/htrflow_core/volume.py</code> <pre><code>def images(self):  # -&gt; Generator[np.ndarray]:\n    \"\"\"Yields the volume's original input images\"\"\"\n    for page in self.pages:\n        yield page.image\n</code></pre>"},{"location":"api/volume/#htrflow_core.volume.Volume.pickle","title":"<code>pickle(directory='.cache', filename=None)</code>","text":"<p>Pickle volume</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str</code> <p>Where to save the pickle file</p> <code>'.cache'</code> <code>filename</code> <code>Optional[str]</code> <p>Name of pickle file, optional. Defaults to \"volume_{volume label}.pickle\" if left as None</p> <code>None</code> <p>Returns:</p> Type Description <p>The path to the pickled file.</p> Source code in <code>src/htrflow_core/volume.py</code> <pre><code>def pickle(self, directory: str=\".cache\", filename: Optional[str] = None):\n    \"\"\"Pickle volume\n\n    Arguments:\n        directory: Where to save the pickle file\n        filename: Name of pickle file, optional. Defaults to\n            \"volume_{volume label}.pickle\" if left as None\n\n    Returns:\n        The path to the pickled file.\n    \"\"\"\n    os.makedirs(directory, exist_ok=True)\n    filename = f\"volume_{self.label}.pickle\" if filename is None else filename\n    path = os.path.join(directory, filename)\n    with open(path, 'wb') as f:\n        pickle.dump(self, f)\n    return path\n</code></pre>"},{"location":"api/volume/#htrflow_core.volume.Volume.save","title":"<code>save(directory='outputs', format_='alto')</code>","text":"<p>Save volume</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str</code> <p>Output directory</p> <code>'outputs'</code> <code>format_</code> <code>Literal['alto', 'page', 'txt']</code> <p>Output format</p> <code>'alto'</code> Source code in <code>src/htrflow_core/volume.py</code> <pre><code>def save(self, directory: str=\"outputs\", format_: Literal[\"alto\", \"page\", \"txt\"] = \"alto\") -&gt; None:\n    \"\"\"Save volume\n\n    Arguments:\n        directory: Output directory\n        format_: Output format\n    \"\"\"\n    serialization.save_volume(self, format_, directory)\n</code></pre>"},{"location":"api/volume/#htrflow_core.volume.Volume.segments","title":"<code>segments(depth=None)</code>","text":"<p>Yields the volume's segments at <code>depth</code></p> <p>Parameters:</p> Name Type Description Default <code>depth</code> <code>int | None</code> <p>Which depth segments to yield. Defaults to None, which returns the leaf nodes (maximum depth).</p> <code>None</code> Source code in <code>src/htrflow_core/volume.py</code> <pre><code>def segments(self, depth: Optional[int] = None): # -&gt; Iterable[np.ndarray]:\n    \"\"\"Yields the volume's segments at `depth`\n\n    Args:\n        depth (int | None): Which depth segments to yield. Defaults to None, which\n            returns the leaf nodes (maximum depth).\n    \"\"\"\n\n    if depth is None:\n        for node in self.leaves():\n            yield node.image\n    else:\n        for page in self.pages:\n            for node in page.traverse(lambda node: node.depth == depth):\n                yield node.image\n</code></pre>"},{"location":"api/volume/#htrflow_core.volume.Volume.update","title":"<code>update(results)</code>","text":"<p>Update the volume with model results</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>list[Result]</code> <p>A list of results where the i:th result corresponds to the volume's i:th leaf node.</p> required Source code in <code>src/htrflow_core/volume.py</code> <pre><code>def update(self, results: list[Result]) -&gt; None:\n    \"\"\"\n    Update the volume with model results\n\n    Arguments:\n        results: A list of results where the i:th result corresponds\n            to the volume's i:th leaf node.\n    \"\"\"\n    leaves = list(self.leaves())\n    if len(leaves) != len(results):\n        raise ValueError(f\"Size of input ({len(results)}) does not match \"\n                         f\"the size of the tree ({len(leaves)})\")\n\n    # Update the leaves of the tree\n    for leaf, result in zip(leaves, results):\n\n        # If the result has segments, segment the leaf\n        if result.segments:\n            leaf.segment(result.segments)\n\n        # If the result has texts, add them to the new leaves (which\n        # may be other than `leaves` if the result also had a segmentation)\n        if result.texts:\n            for new_leaf, text in zip(leaf.leaves(), result.texts):\n                new_leaf.add_text(text)\n</code></pre>"},{"location":"api/volume/#htrflow_core.results.RecognizedText","title":"<code>RecognizedText</code>  <code>dataclass</code>","text":"<p>Recognized text class</p> <p>This class represents a result from a text recognition model.</p> <p>Attributes:</p> Name Type Description <code>texts</code> <code>Sequence[str]</code> <p>A sequence of candidate texts</p> <code>scores</code> <code>Sequence[float]</code> <p>The scores of the candidate texts</p> Source code in <code>src/htrflow_core/results.py</code> <pre><code>@dataclass\nclass RecognizedText:\n    \"\"\"Recognized text class\n\n    This class represents a result from a text recognition model.\n\n    Attributes:\n        texts: A sequence of candidate texts\n        scores: The scores of the candidate texts\n    \"\"\"\n    texts: Sequence[str]\n    scores: Sequence[float]\n\n    def top_candidate(self):\n        \"\"\"The best candidate text\"\"\"\n        return self.texts[self.scores.index(self.top_score())]\n\n    def top_score(self):\n        \"\"\"The highest score\"\"\"\n        return max(self.scores)\n</code></pre>"},{"location":"api/volume/#htrflow_core.results.RecognizedText.top_candidate","title":"<code>top_candidate()</code>","text":"<p>The best candidate text</p> Source code in <code>src/htrflow_core/results.py</code> <pre><code>def top_candidate(self):\n    \"\"\"The best candidate text\"\"\"\n    return self.texts[self.scores.index(self.top_score())]\n</code></pre>"},{"location":"api/volume/#htrflow_core.results.RecognizedText.top_score","title":"<code>top_score()</code>","text":"<p>The highest score</p> Source code in <code>src/htrflow_core/results.py</code> <pre><code>def top_score(self):\n    \"\"\"The highest score\"\"\"\n    return max(self.scores)\n</code></pre>"},{"location":"api/volume/#htrflow_core.results.Result","title":"<code>Result</code>  <code>dataclass</code>","text":"<p>Result class</p> <p>This class bundles segmentation and text recognition results</p> <p>Returns:</p> Name Type Description <code>image</code> <p>The original imaage</p> <code>metadata</code> <p>Metadata associated with the result</p> <code>segments</code> <p>Segments (may be empty)</p> <code>texts</code> <p>Texts (may be empty)</p> Source code in <code>src/htrflow_core/results.py</code> <pre><code>@dataclass\nclass Result:\n    \"\"\"Result class\n\n    This class bundles segmentation and text recognition results\n\n    Returns:\n        image: The original imaage\n        metadata: Metadata associated with the result\n        segments: Segments (may be empty)\n        texts: Texts (may be empty)\n    \"\"\"\n\n    image: np.ndarray\n    metadata: dict\n    segments: Sequence[Segment] = field(default_factory=list)\n    texts: Sequence[RecognizedText] = field(default_factory=list)\n\n    @classmethod\n    def text_recognition_result(cls, image: np.ndarray, metadata: dict, text: RecognizedText) -&gt; \"Result\":\n        \"\"\"Create a text recognition result\n\n        Arguments:\n            image: The original image\n            metadata: Result metadata\n            text: The recognized text\n\n        Returns:\n            A Result instance with the specified data and no segments.\n        \"\"\"\n        return cls(image, metadata, texts=[text])\n\n    @classmethod\n    def segmentation_result(cls, image: np.ndarray, metadata: dict, segments: Sequence[Segment]) -&gt; \"Result\":\n        \"\"\"Create a segmentation result\n\n        Arguments:\n            image: The original image\n            metadata: Result metadata\n            segments: The segments\n\n        Returns:\n            A Result instance with the specified data and no texts.\n        \"\"\"\n        return cls(image, metadata, segments=segments)\n</code></pre>"},{"location":"api/volume/#htrflow_core.results.Result.segmentation_result","title":"<code>segmentation_result(image, metadata, segments)</code>  <code>classmethod</code>","text":"<p>Create a segmentation result</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>The original image</p> required <code>metadata</code> <code>dict</code> <p>Result metadata</p> required <code>segments</code> <code>Sequence[Segment]</code> <p>The segments</p> required <p>Returns:</p> Type Description <code>Result</code> <p>A Result instance with the specified data and no texts.</p> Source code in <code>src/htrflow_core/results.py</code> <pre><code>@classmethod\ndef segmentation_result(cls, image: np.ndarray, metadata: dict, segments: Sequence[Segment]) -&gt; \"Result\":\n    \"\"\"Create a segmentation result\n\n    Arguments:\n        image: The original image\n        metadata: Result metadata\n        segments: The segments\n\n    Returns:\n        A Result instance with the specified data and no texts.\n    \"\"\"\n    return cls(image, metadata, segments=segments)\n</code></pre>"},{"location":"api/volume/#htrflow_core.results.Result.text_recognition_result","title":"<code>text_recognition_result(image, metadata, text)</code>  <code>classmethod</code>","text":"<p>Create a text recognition result</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>The original image</p> required <code>metadata</code> <code>dict</code> <p>Result metadata</p> required <code>text</code> <code>RecognizedText</code> <p>The recognized text</p> required <p>Returns:</p> Type Description <code>Result</code> <p>A Result instance with the specified data and no segments.</p> Source code in <code>src/htrflow_core/results.py</code> <pre><code>@classmethod\ndef text_recognition_result(cls, image: np.ndarray, metadata: dict, text: RecognizedText) -&gt; \"Result\":\n    \"\"\"Create a text recognition result\n\n    Arguments:\n        image: The original image\n        metadata: Result metadata\n        text: The recognized text\n\n    Returns:\n        A Result instance with the specified data and no segments.\n    \"\"\"\n    return cls(image, metadata, texts=[text])\n</code></pre>"},{"location":"api/volume/#htrflow_core.results.Segment","title":"<code>Segment</code>  <code>dataclass</code>","text":"<p>Segment class</p> <p>Attributes:</p> Name Type Description <code>bbox</code> <code>tuple[int, int, int, int]</code> <p>The segment's bounding box as a tuple of coordinates (x1, x2, y1, y2)</p> <code>mask</code> <code>Optional[ndarray]</code> <p>The segment's mask, if available. The mask is relative to the bounding box.</p> <code>score</code> <code>Optional[float]</code> <p>Segment confidence score</p> <code>class_label</code> <code>Optional[str]</code> <p>Segment label, if available</p> <code>polygon</code> <code>list[tuple]</code> <p>An approximation of the segment mask, !relative to the parent!</p> Source code in <code>src/htrflow_core/results.py</code> <pre><code>@dataclass\nclass Segment:\n    \"\"\"Segment class\n\n    Attributes:\n        bbox: The segment's bounding box as a tuple of coordinates (x1, x2, y1, y2)\n        mask: The segment's mask, if available. The mask is relative to the bounding box.\n        score: Segment confidence score\n        class_label: Segment label, if available\n        polygon: An approximation of the segment mask, !relative to the parent!\n    \"\"\"\n\n    bbox: tuple[int, int, int, int]\n    mask: Optional[np.ndarray]\n    polygon: list[tuple] = None\n    score: Optional[float] = None\n    class_label: Optional[str] = None\n    # baseline: list[tuple] ?\n\n    @classmethod\n    def from_bbox(cls, bbox, **kwargs):\n        \"\"\"Create a segment from a bounding box\"\"\"\n        mask = None\n        polygon = image.bbox2polygon(bbox)\n        return cls(bbox, mask, polygon, **kwargs)\n\n    @classmethod\n    def from_mask(cls, mask, **kwargs):\n        \"\"\"Create a segment from a mask\n\n        Args:\n            mask: A binary mask, of same shape as original image.\n        \"\"\"\n        bbox = image.mask2bbox(mask)\n        polygon = image.mask2polygon(mask)\n        cropped_mask = image.crop(mask, bbox)\n        return cls(bbox, cropped_mask, polygon, **kwargs)\n\n    @classmethod\n    def from_baseline(cls, baseline, **kwargs):\n        \"\"\"Create a segment from a baseline\"\"\"\n        raise NotImplementedError()\n</code></pre>"},{"location":"api/volume/#htrflow_core.results.Segment.from_baseline","title":"<code>from_baseline(baseline, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a segment from a baseline</p> Source code in <code>src/htrflow_core/results.py</code> <pre><code>@classmethod\ndef from_baseline(cls, baseline, **kwargs):\n    \"\"\"Create a segment from a baseline\"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"api/volume/#htrflow_core.results.Segment.from_bbox","title":"<code>from_bbox(bbox, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a segment from a bounding box</p> Source code in <code>src/htrflow_core/results.py</code> <pre><code>@classmethod\ndef from_bbox(cls, bbox, **kwargs):\n    \"\"\"Create a segment from a bounding box\"\"\"\n    mask = None\n    polygon = image.bbox2polygon(bbox)\n    return cls(bbox, mask, polygon, **kwargs)\n</code></pre>"},{"location":"api/volume/#htrflow_core.results.Segment.from_mask","title":"<code>from_mask(mask, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a segment from a mask</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <p>A binary mask, of same shape as original image.</p> required Source code in <code>src/htrflow_core/results.py</code> <pre><code>@classmethod\ndef from_mask(cls, mask, **kwargs):\n    \"\"\"Create a segment from a mask\n\n    Args:\n        mask: A binary mask, of same shape as original image.\n    \"\"\"\n    bbox = image.mask2bbox(mask)\n    polygon = image.mask2polygon(mask)\n    cropped_mask = image.crop(mask, bbox)\n    return cls(bbox, cropped_mask, polygon, **kwargs)\n</code></pre>"},{"location":"notebooks/demo/","title":"Demos","text":"In\u00a0[1]: Copied! <pre>import random\nrandom.seed(123)\n</pre> import random random.seed(123) In\u00a0[2]: Copied! <pre>from htrflow_core.volume import Volume\n\nimages = ['../assets/demo_image.jpg'] * 5 \n\nvolume = Volume(images)\n</pre> from htrflow_core.volume import Volume  images = ['../assets/demo_image.jpg'] * 5   volume = Volume(images) <p>The <code>Volume</code> instance holds a tree. We see the root <code>node</code> and its five children, each representing one input image:</p> In\u00a0[3]: Copied! <pre>print(volume)\n</pre> print(volume) <pre>\u2514\u2500\u2500&lt;htrflow_core.volume.Node object at 0x7f5aa834c1c0&gt;\n    \u251c\u2500\u2500626x1629 image demo_image\n    \u251c\u2500\u2500626x1629 image demo_image\n    \u251c\u2500\u2500626x1629 image demo_image\n    \u251c\u2500\u2500626x1629 image demo_image\n    \u2514\u2500\u2500626x1629 image demo_image\n</pre> <p>The images are available through <code>volume.images()</code>. We pass them through a segmentation model:</p> In\u00a0[4]: Copied! <pre>from htrflow_core.models.dummy_models import SegmentationModel\n\nmodel = SegmentationModel()\nresults = model(volume.images())\nprint(results[0])\n</pre> from htrflow_core.models.dummy_models import SegmentationModel  model = SegmentationModel() results = model(volume.images()) print(results[0]) <pre>SegmentationResult(metadata={'model_name': 'SegmentationModel'}, image=array([[[118, 120, 128],\n        [115, 117, 125],\n        [114, 116, 124],\n        ...,\n        [215, 219, 220],\n        [209, 213, 214],\n        [206, 210, 211]],\n\n       [[110, 112, 120],\n        [110, 112, 120],\n        [110, 112, 120],\n        ...,\n        [211, 215, 216],\n        [207, 211, 212],\n        [209, 213, 214]],\n\n       [[109, 112, 120],\n        [109, 112, 120],\n        [104, 107, 115],\n        ...,\n        [207, 211, 212],\n        [205, 209, 210],\n        [209, 213, 214]],\n\n       ...,\n\n       [[146, 152, 151],\n        [147, 153, 152],\n        [147, 153, 152],\n        ...,\n        [212, 218, 213],\n        [214, 222, 211],\n        [211, 221, 204]],\n\n       [[144, 150, 149],\n        [146, 152, 151],\n        [148, 154, 153],\n        ...,\n        [217, 223, 212],\n        [220, 231, 205],\n        [216, 234, 187]],\n\n       [[147, 153, 152],\n        [149, 155, 154],\n        [151, 157, 156],\n        ...,\n        [214, 221, 208],\n        [214, 228, 194],\n        [208, 231, 169]]], dtype=uint8), segments=[Segment(bbox=(345, 751, 11, 167), mask=array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8), polygon=array([[345,  85],\n       [356, 115],\n       [393, 140],\n       [527, 167],\n       [672, 151],\n       [726, 127],\n       [751,  93],\n       [740,  63],\n       [703,  38],\n       [570,  11],\n       [417,  29],\n       [365,  55]], dtype=int32), score=0.7689563885870707, class_label='region')])\n</pre> <p>The results are a list of <code>SegmentationResult</code>. To apply the results to the input images, we pass them back to the volume with its <code>update</code> method. It returns the new regions as a list of images.</p> In\u00a0[5]: Copied! <pre>regions = volume.update(results)\n</pre> regions = volume.update(results) <p>The volume tree has now grown:</p> In\u00a0[6]: Copied! <pre>print(volume)\n</pre> print(volume) <pre>\u2514\u2500\u2500&lt;htrflow_core.volume.Node object at 0x7f5aa834c1c0&gt;\n    \u251c\u2500\u2500626x1629 image demo_image\n    \u2502   \u2514\u2500\u2500156x406 region at (345, 11)\n    \u251c\u2500\u2500626x1629 image demo_image\n    \u2502   \u251c\u2500\u2500117x406 region at (17, 0)\n    \u2502   \u251c\u2500\u2500156x406 region at (948, 262)\n    \u2502   \u2514\u2500\u2500156x309 region at (0, 85)\n    \u251c\u2500\u2500626x1629 image demo_image\n    \u2502   \u251c\u2500\u2500156x406 region at (480, 173)\n    \u2502   \u251c\u2500\u2500156x406 region at (690, 11)\n    \u2502   \u251c\u2500\u2500149x406 region at (570, 0)\n    \u2502   \u251c\u2500\u2500156x332 region at (1296, 381)\n    \u2502   \u2514\u2500\u2500156x292 region at (0, 16)\n    \u251c\u2500\u2500626x1629 image demo_image\n    \u2502   \u251c\u2500\u250099x213 region at (1415, 0)\n    \u2502   \u2514\u2500\u2500116x406 region at (678, 509)\n    \u2514\u2500\u2500626x1629 image demo_image\n        \u251c\u2500\u2500156x278 region at (0, 234)\n        \u251c\u2500\u2500156x406 region at (786, 133)\n        \u251c\u2500\u2500156x406 region at (1105, 461)\n        \u2514\u2500\u250090x406 region at (442, 0)\n</pre> <p>The new regions can be passed through a segmentation model (such as a line model) again. The <code>update</code> method always updates the leaves of the tree.</p> In\u00a0[7]: Copied! <pre>results = model(volume.segments())\nvolume.update(results)\nprint(volume)\n</pre> results = model(volume.segments()) volume.update(results) print(volume) <pre>\u2514\u2500\u2500&lt;htrflow_core.volume.Node object at 0x7f5aa834c1c0&gt;\n    \u251c\u2500\u2500626x1629 image demo_image\n    \u2502   \u2514\u2500\u2500156x406 region at (345, 11)\n    \u2502       \u251c\u2500\u250037x100 region at (517, 129)\n    \u2502       \u251c\u2500\u250022x100 region at (636, 144)\n    \u2502       \u251c\u2500\u250038x100 region at (543, 125)\n    \u2502       \u251c\u2500\u250038x100 region at (486, 122)\n    \u2502       \u2514\u2500\u250038x69 region at (681, 38)\n    \u251c\u2500\u2500626x1629 image demo_image\n    \u2502   \u251c\u2500\u2500117x406 region at (17, 0)\n    \u2502   \u2502   \u2514\u2500\u250028x100 region at (216, 70)\n    \u2502   \u251c\u2500\u2500156x406 region at (948, 262)\n    \u2502   \u2502   \u251c\u2500\u250033x100 region at (1070, 384)\n    \u2502   \u2502   \u251c\u2500\u250038x87 region at (948, 359)\n    \u2502   \u2502   \u2514\u2500\u250038x57 region at (1296, 329)\n    \u2502   \u2514\u2500\u2500156x309 region at (0, 85)\n    \u2502       \u251c\u2500\u250038x76 region at (7, 159)\n    \u2502       \u251c\u2500\u250038x76 region at (142, 124)\n    \u2502       \u251c\u2500\u250034x76 region at (218, 85)\n    \u2502       \u251c\u2500\u250038x76 region at (215, 125)\n    \u2502       \u2514\u2500\u250038x76 region at (52, 105)\n    \u251c\u2500\u2500626x1629 image demo_image\n    \u2502   \u251c\u2500\u2500156x406 region at (480, 173)\n    \u2502   \u2502   \u251c\u2500\u250038x100 region at (623, 272)\n    \u2502   \u2502   \u251c\u2500\u250038x100 region at (498, 270)\n    \u2502   \u2502   \u251c\u2500\u250038x100 region at (561, 244)\n    \u2502   \u2502   \u2514\u2500\u250038x100 region at (652, 261)\n    \u2502   \u251c\u2500\u2500156x406 region at (690, 11)\n    \u2502   \u2502   \u251c\u2500\u250038x82 region at (690, 122)\n    \u2502   \u2502   \u251c\u2500\u250038x95 region at (690, 13)\n    \u2502   \u2502   \u251c\u2500\u250037x54 region at (690, 129)\n    \u2502   \u2502   \u251c\u2500\u250038x100 region at (919, 95)\n    \u2502   \u2502   \u2514\u2500\u250038x100 region at (805, 59)\n    \u2502   \u251c\u2500\u2500149x406 region at (570, 0)\n    \u2502   \u2502   \u2514\u2500\u250023x71 region at (904, 125)\n    \u2502   \u251c\u2500\u2500156x332 region at (1296, 381)\n    \u2502   \u2502   \u251c\u2500\u250038x53 region at (1296, 403)\n    \u2502   \u2502   \u251c\u2500\u250035x82 region at (1469, 381)\n    \u2502   \u2502   \u2514\u2500\u250038x82 region at (1328, 457)\n    \u2502   \u2514\u2500\u2500156x292 region at (0, 16)\n    \u2502       \u2514\u2500\u250038x65 region at (0, 129)\n    \u251c\u2500\u2500626x1629 image demo_image\n    \u2502   \u251c\u2500\u250099x213 region at (1415, 0)\n    \u2502   \u2502   \u251c\u2500\u250024x52 region at (1426, 71)\n    \u2502   \u2502   \u251c\u2500\u250024x52 region at (1463, 37)\n    \u2502   \u2502   \u2514\u2500\u250024x52 region at (1525, 31)\n    \u2502   \u2514\u2500\u2500116x406 region at (678, 509)\n    \u2502       \u251c\u2500\u250028x100 region at (929, 544)\n    \u2502       \u2514\u2500\u250028x76 region at (1007, 512)\n    \u2514\u2500\u2500626x1629 image demo_image\n        \u251c\u2500\u2500156x278 region at (0, 234)\n        \u2502   \u2514\u2500\u250038x68 region at (144, 330)\n        \u251c\u2500\u2500156x406 region at (786, 133)\n        \u2502   \u251c\u2500\u250038x100 region at (891, 223)\n        \u2502   \u251c\u2500\u250038x64 region at (786, 154)\n        \u2502   \u251c\u2500\u250038x100 region at (1000, 245)\n        \u2502   \u2514\u2500\u250038x100 region at (911, 242)\n        \u251c\u2500\u2500156x406 region at (1105, 461)\n        \u2502   \u251c\u2500\u250029x100 region at (1170, 587)\n        \u2502   \u251c\u2500\u250038x100 region at (1194, 571)\n        \u2502   \u2514\u2500\u250038x100 region at (1219, 509)\n        \u2514\u2500\u250090x406 region at (442, 0)\n            \u251c\u2500\u250022x91 region at (442, 14)\n            \u251c\u2500\u250013x67 region at (780, 0)\n            \u251c\u2500\u250022x100 region at (681, 18)\n            \u251c\u2500\u250021x100 region at (554, 0)\n            \u2514\u2500\u250022x100 region at (667, 6)\n</pre> <p>When the segmentation is done, the segments can be passed to a text recognition model. The results are passed to the workbench in the same manner as before:</p> In\u00a0[8]: Copied! <pre>from htrflow_core.models.dummy_models import RecognitionModel\n\nrecognition_model = RecognitionModel()\nresults = recognition_model(volume.segments())\nvolume.update(results)\nprint(volume)\n</pre> from htrflow_core.models.dummy_models import RecognitionModel  recognition_model = RecognitionModel() results = recognition_model(volume.segments()) volume.update(results) print(volume) <pre>\u2514\u2500\u2500&lt;htrflow_core.volume.Node object at 0x7f5aa834c1c0&gt;\n    \u251c\u2500\u2500626x1629 image demo_image\n    \u2502   \u2514\u2500\u2500156x406 region at (345, 11)\n    \u2502       \u251c\u2500\u250037x100 region at (517, 129) \"Dolor velit non non tempora magnam ut adipisci.\"\n    \u2502       \u251c\u2500\u250022x100 region at (636, 144) \"Dolor quiquia quisquam adipisci velit velit quiquia quiquia.\"\n    \u2502       \u251c\u2500\u250038x100 region at (543, 125) \"Ipsum labore dolorem ut neque ipsum velit.\"\n    \u2502       \u251c\u2500\u250038x100 region at (486, 122) \"Consectetur est numquam voluptatem quiquia ipsum.\"\n    \u2502       \u2514\u2500\u250038x69 region at (681, 38) \"Magnam etincidunt consectetur neque quaerat ut sit ipsum.\"\n    \u251c\u2500\u2500626x1629 image demo_image\n    \u2502   \u251c\u2500\u2500117x406 region at (17, 0)\n    \u2502   \u2502   \u2514\u2500\u250028x100 region at (216, 70) \"Modi sed non tempora.\"\n    \u2502   \u251c\u2500\u2500156x406 region at (948, 262)\n    \u2502   \u2502   \u251c\u2500\u250033x100 region at (1070, 384) \"Numquam quiquia ut etincidunt sit quaerat adipisci.\"\n    \u2502   \u2502   \u251c\u2500\u250038x87 region at (948, 359) \"Est etincidunt dolore modi.\"\n    \u2502   \u2502   \u2514\u2500\u250038x57 region at (1296, 329) \"Dolore ut tempora numquam voluptatem dolorem etincidunt non.\"\n    \u2502   \u2514\u2500\u2500156x309 region at (0, 85)\n    \u2502       \u251c\u2500\u250038x76 region at (7, 159) \"Numquam amet quisquam magnam modi.\"\n    \u2502       \u251c\u2500\u250038x76 region at (142, 124) \"Dolorem dolorem eius aliquam eius.\"\n    \u2502       \u251c\u2500\u250034x76 region at (218, 85) \"Eius tempora modi sit.\"\n    \u2502       \u251c\u2500\u250038x76 region at (215, 125) \"Tempora labore velit dolor.\"\n    \u2502       \u2514\u2500\u250038x76 region at (52, 105) \"Consectetur neque labore porro quiquia.\"\n    \u251c\u2500\u2500626x1629 image demo_image\n    \u2502   \u251c\u2500\u2500156x406 region at (480, 173)\n    \u2502   \u2502   \u251c\u2500\u250038x100 region at (623, 272) \"Quaerat sed ipsum tempora.\"\n    \u2502   \u2502   \u251c\u2500\u250038x100 region at (498, 270) \"Ipsum aliquam consectetur dolor.\"\n    \u2502   \u2502   \u251c\u2500\u250038x100 region at (561, 244) \"Sed magnam aliquam aliquam dolor.\"\n    \u2502   \u2502   \u2514\u2500\u250038x100 region at (652, 261) \"Sed dolor amet sed adipisci etincidunt.\"\n    \u2502   \u251c\u2500\u2500156x406 region at (690, 11)\n    \u2502   \u2502   \u251c\u2500\u250038x82 region at (690, 122) \"Voluptatem aliquam aliquam porro amet.\"\n    \u2502   \u2502   \u251c\u2500\u250038x95 region at (690, 13) \"Modi aliquam quiquia etincidunt labore.\"\n    \u2502   \u2502   \u251c\u2500\u250037x54 region at (690, 129) \"Tempora dolore quiquia ipsum neque consectetur tempora.\"\n    \u2502   \u2502   \u251c\u2500\u250038x100 region at (919, 95) \"Tempora labore modi ut non.\"\n    \u2502   \u2502   \u2514\u2500\u250038x100 region at (805, 59) \"Ut dolorem labore dolore consectetur.\"\n    \u2502   \u251c\u2500\u2500149x406 region at (570, 0)\n    \u2502   \u2502   \u2514\u2500\u250023x71 region at (904, 125) \"Est labore dolor est.\"\n    \u2502   \u251c\u2500\u2500156x332 region at (1296, 381)\n    \u2502   \u2502   \u251c\u2500\u250038x53 region at (1296, 403) \"Neque eius adipisci amet voluptatem consectetur.\"\n    \u2502   \u2502   \u251c\u2500\u250035x82 region at (1469, 381) \"Voluptatem magnam voluptatem labore sed dolore voluptatem.\"\n    \u2502   \u2502   \u2514\u2500\u250038x82 region at (1328, 457) \"Dolore ut magnam voluptatem etincidunt amet adipisci.\"\n    \u2502   \u2514\u2500\u2500156x292 region at (0, 16)\n    \u2502       \u2514\u2500\u250038x65 region at (0, 129) \"Etincidunt etincidunt quiquia porro velit.\"\n    \u251c\u2500\u2500626x1629 image demo_image\n    \u2502   \u251c\u2500\u250099x213 region at (1415, 0)\n    \u2502   \u2502   \u251c\u2500\u250024x52 region at (1426, 71) \"Etincidunt etincidunt dolorem modi dolorem.\"\n    \u2502   \u2502   \u251c\u2500\u250024x52 region at (1463, 37) \"Neque quaerat dolorem magnam.\"\n    \u2502   \u2502   \u2514\u2500\u250024x52 region at (1525, 31) \"Sed aliquam dolor quisquam numquam.\"\n    \u2502   \u2514\u2500\u2500116x406 region at (678, 509)\n    \u2502       \u251c\u2500\u250028x100 region at (929, 544) \"Velit tempora non quiquia magnam ipsum sed.\"\n    \u2502       \u2514\u2500\u250028x76 region at (1007, 512) \"Dolor sed velit quisquam dolor.\"\n    \u2514\u2500\u2500626x1629 image demo_image\n        \u251c\u2500\u2500156x278 region at (0, 234)\n        \u2502   \u2514\u2500\u250038x68 region at (144, 330) \"Amet adipisci quaerat quiquia sit dolor numquam ut.\"\n        \u251c\u2500\u2500156x406 region at (786, 133)\n        \u2502   \u251c\u2500\u250038x100 region at (891, 223) \"Etincidunt velit ut neque labore quisquam.\"\n        \u2502   \u251c\u2500\u250038x64 region at (786, 154) \"Aliquam labore aliquam quaerat consectetur.\"\n        \u2502   \u251c\u2500\u250038x100 region at (1000, 245) \"Ut non numquam ut.\"\n        \u2502   \u2514\u2500\u250038x100 region at (911, 242) \"Ipsum sed non dolore eius consectetur.\"\n        \u251c\u2500\u2500156x406 region at (1105, 461)\n        \u2502   \u251c\u2500\u250029x100 region at (1170, 587) \"Sed sed magnam tempora velit.\"\n        \u2502   \u251c\u2500\u250038x100 region at (1194, 571) \"Numquam quisquam dolore ut non.\"\n        \u2502   \u2514\u2500\u250038x100 region at (1219, 509) \"Sit amet ipsum neque neque adipisci consectetur.\"\n        \u2514\u2500\u250090x406 region at (442, 0)\n            \u251c\u2500\u250022x91 region at (442, 14) \"Ipsum ut eius sit porro sit.\"\n            \u251c\u2500\u250013x67 region at (780, 0) \"Dolorem voluptatem sed voluptatem non modi quisquam.\"\n            \u251c\u2500\u250022x100 region at (681, 18) \"Sed amet labore dolorem velit aliquam.\"\n            \u251c\u2500\u250021x100 region at (554, 0) \"Sit non amet velit dolorem dolore labore.\"\n            \u2514\u2500\u250022x100 region at (667, 6) \"Dolorem amet amet modi voluptatem.\"\n</pre> In\u00a0[9]: Copied! <pre># Access image 0, region 0, subregion 0\nvolume[0, 0, 0]\n\n# Access image 0, region 0\nvolume[0, 0]\n</pre> # Access image 0, region 0, subregion 0 volume[0, 0, 0]  # Access image 0, region 0 volume[0, 0] Out[9]: <pre>&lt;htrflow_core.volume.RegionNode at 0x7f5a496ef1f0&gt;</pre> <p>The image associated with each node is accessed through the <code>image</code> attribute. The image isn't stored directly in the node, instead, the node refers to the parent image, and crops it according to its box:</p> <pre>class BaseImageNode:\n    \n    @property\n    def image(self):\n        x1, x2, y1, y2 = self.box\n        return self.parent.image[y1:y2, x1:x2]\n    \n    ...\n</pre> In\u00a0[10]: Copied! <pre>volume[0, 0, 0].image\n</pre> volume[0, 0, 0].image Out[10]: <pre>array([[[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]],\n\n       [[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]],\n\n       [[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]],\n\n       ...,\n\n       [[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]],\n\n       [[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]],\n\n       [[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]]], dtype=uint8)</pre> In\u00a0[11]: Copied! <pre>print(volume[0].coordinate)\n</pre> print(volume[0].coordinate) <pre>\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[11], line 1\n----&gt; 1 print(volume[0].coordinate)\n\nAttributeError: 'PageNode' object has no attribute 'coordinate'</pre> <p>For first-level regions <code>coordinate</code> is the same as the corner of the segment bounding box.</p> In\u00a0[12]: Copied! <pre>print('Coordinate:', volume[0, 0].coordinate)\nprint('Bounding box:', volume[0, 0].data['segment'].box, '(x1, x2, y1, y2)')\n</pre> print('Coordinate:', volume[0, 0].coordinate) print('Bounding box:', volume[0, 0].data['segment'].box, '(x1, x2, y1, y2)') <pre>\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[12], line 1\n----&gt; 1 print('Coordinate:', volume[0, 0].coordinate)\n      2 print('Bounding box:', volume[0, 0].data['segment'].box, '(x1, x2, y1, y2)')\n\nAttributeError: 'RegionNode' object has no attribute 'coordinate'</pre> <p>But for nested regions the two differ, because <code>coordinate</code> is relative to the original image, while the segment bounding box is relative to the parent region.</p> In\u00a0[13]: Copied! <pre>print('Global coordinate:', volume[0, 0, 0].coordinate)\nprint('Local bounding box:', volume[0, 0, 0].data['segment'].box)\n</pre> print('Global coordinate:', volume[0, 0, 0].coordinate) print('Local bounding box:', volume[0, 0, 0].data['segment'].box) <pre>\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[13], line 1\n----&gt; 1 print('Global coordinate:', volume[0, 0, 0].coordinate)\n      2 print('Local bounding box:', volume[0, 0, 0].data['segment'].box)\n\nAttributeError: 'RegionNode' object has no attribute 'coordinate'</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/demo/#models-inferencers","title":"Models / inferencers\u00b6","text":"<p>Models &amp; inferencers accept lists of images, and return lists of results (either segmentation or recognition results)</p> <p>I have made a dummy <code>SegmentationModel</code> and <code>RecognitionModel</code> in <code>models.py</code>. These do the same thing as the current inferencers.</p> <pre>class SegmentationModel:\n    def __call__(self, images: list[np.ndarray]) -&gt; list[SegmentationResult]:\n        ...\n\n\n@dataclass\nclass SegmentationResult:\n    boxes: np.ndarray\n    masks: np.ndarray\n    scores: np.ndarray\n    labels: np.ndarray\n</pre> <p>(It would be nice to wrap all models in a \"batching\" function, which divides an input list into chunks if it is too long) -&gt; This is a card in DevOps</p>"},{"location":"notebooks/demo/#using-the-volume-class","title":"Using the Volume class\u00b6","text":"<p>To load images, create a <code>Volume</code>. The name of this class is not set in stone... It represents what Catrin called a \"batch\", a divison of an archive volume, but I don't want to use \"batch\" because of potential confusion with a model's batch (the number of inputs it operates on simultaneously).</p>"},{"location":"notebooks/demo/#accessing-nodes","title":"Accessing nodes\u00b6","text":"<p>Specific nodes are accessed by tuple indexing. Here we extract the first line of the first region of the first image:</p>"},{"location":"notebooks/demo/#coordinates","title":"Coordinates\u00b6","text":"<p>All nodes have a <code>coordinate</code> attribute. This is the location of the node's top-left corner relative to the original image. The base image node's coordinate is thus (0,0):</p>"},{"location":"notebooks/demo2/","title":"Demo2","text":"In\u00a0[\u00a0]: Copied! <pre>from htrflow_core.models.huggingface.trocr import TrOCR\nfrom htrflow_core.models.ultralytics.yolo import YOLO\nfrom htrflow_core.volume import Volume\n\nimg = '../assets/demo_image.jpg'\nvol = Volume([img, img])\n\nseg_model = YOLO('ultralyticsplus/yolov8s')\nres = seg_model(vol.images())  # vol.segments() is also possible since it points to the images\nvol.update(res)\n\nrec_model = TrOCR()\nres = rec_model(vol.segments())\nvol.update(res)\n\n# The final volume\nprint(vol)\n\n# Saves at outputs/&lt;image_name&gt;.xml, since the two demo images are called the same, we get only one output file \nvol.save('outputs', 'alto')\n</pre> from htrflow_core.models.huggingface.trocr import TrOCR from htrflow_core.models.ultralytics.yolo import YOLO from htrflow_core.volume import Volume  img = '../assets/demo_image.jpg' vol = Volume([img, img])  seg_model = YOLO('ultralyticsplus/yolov8s') res = seg_model(vol.images())  # vol.segments() is also possible since it points to the images vol.update(res)  rec_model = TrOCR() res = rec_model(vol.segments()) vol.update(res)  # The final volume print(vol)  # Saves at outputs/.xml, since the two demo images are called the same, we get only one output file  vol.save('outputs', 'alto')"}]}